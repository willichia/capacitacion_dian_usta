{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4641eb06-d3e6-4179-a3bf-03b5e51c2e91",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# **Generaci贸n del Conjunto de Datos de Origen**\n",
    "\n",
    "**Objetivo:** El primer paso en cualquier proyecto de datos es tener datos. En esta celda, simulamos el proceso de recibir datos crudos de los distintos sistemas de una empresa de e-commerce. En lugar de usar un archivo CSV est谩tico, generamos los datos mediante programaci贸n para crear un escenario din谩mico y realista.\n",
    "\n",
    "---\n",
    "## **Simulando un Ecosistema de Datos Real**\n",
    "\n",
    "En el mundo real, los datos no provienen de un solo lugar. Llegan de m煤ltiples fuentes:\n",
    "\n",
    "* Un sistema **CRM** para la gesti贸n de usuarios.\n",
    "* Un **ERP** para el manejo de proveedores y productos.\n",
    "* Una **plataforma de ventas** que registra los pedidos.\n",
    "* Un **sistema de log铆stica** para gestionar las devoluciones.\n",
    "\n",
    "Este script utiliza Python, PySpark y la librer铆a **`Faker`** para imitar este ecosistema, creando cinco DataFrames distintos que representan estas fuentes.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "## **Componentes Clave del Script**\n",
    "\n",
    "* **`Faker`**: Es una potente librer铆a de Python que nos permite crear datos falsos pero realistas (nombres, empresas, ciudades, etc.). Es una herramienta fundamental para probar pipelines de datos sin exponer informaci贸n sensible.\n",
    "\n",
    "* **La Semilla de la Reproducibilidad (`SEED = 42`) **: Este es uno de los conceptos m谩s importantes de la celda. Al fijar una \"semilla\", nos aseguramos de que el generador de n煤meros \"aleatorios\" produzca **siempre la misma secuencia**. Esto significa que, sin importar cu谩ntas veces ejecutemos el c贸digo, los datos generados ser谩n id茅nticos. Para un taller, esto es crucial, ya que garantiza que todos los participantes trabajen con el mismo conjunto de datos y obtengan los mismos resultados.\n",
    "\n",
    "* **Las Entidades de Negocio Creadas **: Hemos modelado cinco entidades clave para nuestro negocio simulado, lo que nos dar谩 material para an谩lisis interesantes:\n",
    "    * **`Proveedores`**: 驴De d贸nde vienen nuestros productos?\n",
    "    * **`Usuarios`**: 驴Qui茅nes son nuestros clientes?\n",
    "    * **`Productos`**: 驴Qu茅 vendemos? (Ahora vinculados a un proveedor).\n",
    "    * **`Pedidos`**: El registro de las ventas, el coraz贸n de nuestro negocio.\n",
    "    * **`Devoluciones`**: 驴Qu茅 productos se devuelven y por qu茅?\n",
    "\n",
    "Al finalizar la ejecuci贸n de esta celda, tendremos cinco DataFrames de PySpark cargados en la memoria del cl煤ster, listos para ser procesados e ingeridos en nuestra arquitectura Medallion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a890929-cbbb-4369-a2b9-0500027fbaac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Celda 1: Script para generar un conjunto de datos de e-commerce enriquecido\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from faker import Faker\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# --- SEMILLA PARA REPRODUCIBILIDAD ---\n",
    "# Garantiza que los datos generados sean siempre los mismos.\n",
    "SEED = 42\n",
    "Faker.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# Inicializar Faker y Spark Session\n",
    "fake = Faker('es_ES')\n",
    "# spark = SparkSession.builder.appName(\"Taller de Arquitecturas de Datos\").getOrCreate() # En Databricks, 'spark' ya est谩 disponible\n",
    "\n",
    "# --- 1. GENERACIN DE PROVEEDORES ---\n",
    "def generar_proveedores(n=10):\n",
    "    \"\"\"Genera una lista de proveedores de productos.\"\"\"\n",
    "    return [{'id_proveedor': 500 + i, 'nombre_proveedor': fake.company()} for i in range(n)]\n",
    "\n",
    "# --- 2. GENERACIN DE USUARIOS ---\n",
    "def generar_usuarios(n=100):\n",
    "    \"\"\"Genera una lista de diccionarios de usuarios.\"\"\"\n",
    "    return [{'id_usuario': 1000 + i, 'nombre': fake.name(), 'email': fake.email(), 'fecha_registro': fake.date_time_between(start_date='-2y'), 'ciudad': fake.city()} for i in range(n)]\n",
    "\n",
    "# --- 3. GENERACIN DE PRODUCTOS (Ahora con proveedor) ---\n",
    "def generar_productos(proveedores, n=50):\n",
    "    \"\"\"Genera una lista de productos, asignando un proveedor a cada uno.\"\"\"\n",
    "    categorias = ['Electr贸nica', 'Hogar', 'Ropa', 'Libros', 'Deportes']\n",
    "    data = []\n",
    "    for i in range(n):\n",
    "        data.append({\n",
    "            'id_producto': 2000 + i,\n",
    "            'id_proveedor': random.choice(proveedores)['id_proveedor'],\n",
    "            'nombre_producto': fake.word().capitalize() + \" \" + fake.word(),\n",
    "            'categoria': random.choice(categorias),\n",
    "            'precio_unitario': round(random.uniform(5.0, 250.0), 2)\n",
    "        })\n",
    "    return data\n",
    "\n",
    "# --- 4. GENERACIN DE PEDIDOS (Ahora con m茅todo de pago) ---\n",
    "def generar_pedidos(usuarios, productos, n=500):\n",
    "    \"\"\"Genera una lista de pedidos, vinculando usuarios y productos.\"\"\"\n",
    "    metodos_pago = ['Tarjeta de Cr茅dito', 'PayPal', 'PSE', 'Efectivo']\n",
    "    data = []\n",
    "    for i in range(n):\n",
    "        usuario = random.choice(usuarios)\n",
    "        producto = random.choice(productos)\n",
    "        cantidad = random.randint(1, 5)\n",
    "        data.append({\n",
    "            'id_pedido': 3000 + i,\n",
    "            'id_usuario': usuario['id_usuario'],\n",
    "            'id_producto': producto['id_producto'],\n",
    "            'cantidad': cantidad,\n",
    "            'monto': round(cantidad * producto['precio_unitario'], 2),\n",
    "            'metodo_pago': random.choice(metodos_pago),\n",
    "            'fecha_pedido': fake.date_time_between(start_date=usuario['fecha_registro'])\n",
    "        })\n",
    "    return data\n",
    "\n",
    "# --- 5. GENERACIN DE DEVOLUCIONES ---\n",
    "def generar_devoluciones(pedidos, n=30):\n",
    "    \"\"\"Genera una lista de devoluciones, seleccionando pedidos al azar.\"\"\"\n",
    "    motivos = ['Producto defectuoso', 'No era la talla correcta', 'No cumple expectativas', 'Me arrepent铆 de la compra']\n",
    "    pedidos_devueltos = random.sample(pedidos, n)\n",
    "    data = []\n",
    "    for i, pedido in enumerate(pedidos_devueltos):\n",
    "        data.append({\n",
    "            'id_devolucion': 7000 + i,\n",
    "            'id_pedido': pedido['id_pedido'],\n",
    "            'fecha_devolucion': fake.date_time_between(start_date=pedido['fecha_pedido']),\n",
    "            'motivo': random.choice(motivos)\n",
    "        })\n",
    "    return data\n",
    "\n",
    "# --- CREACIN DE DATAFRAMES EN MEMORIA ---\n",
    "print(\"Generando datos simulados...\")\n",
    "proveedores_data = generar_proveedores(10)\n",
    "usuarios_data = generar_usuarios(100)\n",
    "productos_data = generar_productos(proveedores_data, 50)\n",
    "pedidos_data = generar_pedidos(usuarios_data, productos_data, 500)\n",
    "devoluciones_data = generar_devoluciones(pedidos_data, 30)\n",
    "\n",
    "proveedores_df = spark.createDataFrame(proveedores_data)\n",
    "usuarios_df = spark.createDataFrame(usuarios_data)\n",
    "productos_df = spark.createDataFrame(productos_data)\n",
    "pedidos_df = spark.createDataFrame(pedidos_data)\n",
    "devoluciones_df = spark.createDataFrame(devoluciones_data)\n",
    "\n",
    "print(\"\\n--- DataFrames Creados en Memoria ---\")\n",
    "print(f\"Proveedores: {proveedores_df.count()} registros\")\n",
    "print(f\"Usuarios: {usuarios_df.count()} registros\")\n",
    "print(f\"Productos: {productos_df.count()} registros\")\n",
    "print(f\"Pedidos: {pedidos_df.count()} registros\")\n",
    "print(f\"Devoluciones: {devoluciones_df.count()} registros\")\n",
    "\n",
    "print(\"\\nCelda 1 completada: El conjunto de datos enriquecido est谩 listo para ser ingerido en la capa Bronce.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "de720ecf-6291-40a9-9418-04a675c2b0fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Ingesta a la Capa BRONCE - Persistencia de los Datos de Origen\n",
    "\n",
    "**Objetivo:** El prop贸sito de esta celda es tomar los datos que existen temporalmente en la memoria del cl煤ster (los DataFrames de la Celda 1) y guardarlos como tablas permanentes. Este es el primer paso oficial de nuestro pipeline: la materializaci贸n de los datos en la capa **Bronce**.\n",
    "\n",
    "---\n",
    "## **El Archivo de Datos Crudos**\n",
    "\n",
    "La capa Bronce funciona como el **archivo hist贸rico y fiel** de nuestros datos de origen. Su principal y 煤nica regla es almacenar la informaci贸n **exactamente como fue recibida**, sin aplicar ninguna limpieza, transformaci贸n o validaci贸n.\n",
    "\n",
    "Este enfoque nos proporciona dos ventajas estrat茅gicas:\n",
    "\n",
    "1.  **Auditabilidad y Linaje**: Mantenemos un registro perfecto del estado de los datos en el momento de su ingesta. Esto es crucial para auditor铆as y para rastrear el origen de cualquier dato en las capas posteriores.\n",
    "2.  **Capacidad de Reprocesamiento**: Si en el futuro las reglas de negocio cambian, siempre podemos volver a esta capa Bronce intacta y volver a ejecutar nuestros pipelines de transformaci贸n desde el principio con la nueva l贸gica, sin tener que volver a conectarnos a los sistemas de origen.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "## **Componentes Clave del Script**\n",
    "\n",
    "* **Formato Delta Lake**: No guardamos los datos en un formato simple como CSV. Usamos **Delta Lake**, el est谩ndar en Databricks. Esto convierte nuestro almacenamiento en un sistema transaccional robusto, d谩ndonos garant铆as **ACID** (los trabajos no quedan a medias), un rendimiento optimizado y la capacidad de \"viajar en el tiempo\" a versiones anteriores de los datos.\n",
    "\n",
    "* **`saveAsTable()`**: Este comando es el coraz贸n de la celda. Realiza dos acciones clave:\n",
    "    1.  **Guarda los datos** en el almacenamiento subyacente (como archivos Parquet optimizados).\n",
    "    2.  **Registra la tabla** en el cat谩logo de Databricks (Unity Catalog o Hive Metastore), lo que la hace visible y consultable mediante SQL.\n",
    "\n",
    "* **Organizaci贸n (`USE curso_arquitecturas`)**: Antes de guardar, nos aseguramos de estar en la base de datos correcta. Mantener las tablas de un proyecto dentro de su propio `schema` o base de datos es una pr谩ctica esencial para tener un espacio de trabajo ordenado.\n",
    "\n",
    "Al finalizar la ejecuci贸n de esta celda, nuestros datos ya no son temporales. Se han convertido en cinco tablas Delta persistentes que forman la base de nuestra arquitectura, listas para ser refinadas en la siguiente capa: Plata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37d47329-971a-4dc3-a842-7128c4890a5c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Celda 2: Guardar los DataFrames como Tablas Delta en la Capa Bronce\n",
    "\n",
    "# --- 1. Definir y usar la base de datos para nuestro proyecto ---\n",
    "db_name = \"curso_arquitecturas\"\n",
    "spark.sql(f\"CREATE DATABASE IF NOT EXISTS {db_name}\")\n",
    "spark.sql(f\"USE {db_name}\")\n",
    "\n",
    "print(f\"Usando la base de datos: {db_name}\\n\")\n",
    "\n",
    "# --- 2. Persistir cada DataFrame como una tabla Delta en la capa Bronce ---\n",
    "\n",
    "# Guardar la tabla de proveedores\n",
    "proveedores_df.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"proveedores_bronze\")\n",
    "print(\"Tabla 'proveedores_bronze' guardada exitosamente.\")\n",
    "\n",
    "# Guardar la tabla de usuarios\n",
    "usuarios_df.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"usuarios_bronze\")\n",
    "print(\"Tabla 'usuarios_bronze' guardada exitosamente.\")\n",
    "\n",
    "# Guardar la tabla de productos\n",
    "productos_df.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"mergeSchema\", \"true\")\\\n",
    "    .saveAsTable(\"productos_bronze\")\n",
    "print(\"Tabla 'productos_bronze' guardada exitosamente.\")\n",
    "\n",
    "# Guardar la tabla de pedidos\n",
    "pedidos_df.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"mergeSchema\", \"true\")\\\n",
    "    .saveAsTable(\"pedidos_bronze\")\n",
    "print(\"Tabla 'pedidos_bronze' guardada exitosamente.\")\n",
    "\n",
    "# Guardar la tabla de devoluciones\n",
    "devoluciones_df.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .saveAsTable(\"devoluciones_bronze\")\n",
    "print(\"Tabla 'devoluciones_bronze' guardada exitosamente.\")\n",
    "\n",
    "print(\"\\n隆Proceso completado! Las 5 tablas de la capa Bronce ya est谩n disponibles en el cat谩logo para la siguiente etapa.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4648e81b-4e1f-4aaf-bf33-bfa0b39116c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# **Celda 2.5 (Explicativa): Propiedades ACID y Auditor铆a de Datos en Delta Lake**\n",
    "\n",
    "Antes de proceder con la transformaci贸n de datos a la capa Plata, es importante comprender una caracter铆stica fundamental de las tablas Delta que acabamos de crear: las garant铆as transaccionales **ACID**.\n",
    "\n",
    "-----\n",
    "\n",
    "## **Garant铆as Transaccionales ACID**\n",
    "\n",
    "ACID es un acr贸nimo que designa un conjunto de cuatro propiedades que aseguran la fiabilidad e integridad de los datos durante las operaciones de escritura.\n",
    "\n",
    "  * **Atomicidad (A)**: Asegura que cada transacci贸n se trate como una 煤nica unidad de trabajo que se ejecuta completamente o no se ejecuta en absoluto. Su principal beneficio es la prevenci贸n de la corrupci贸n de datos por escrituras parciales.\n",
    "\n",
    "  * **Consistencia (C)**: Garantiza que cada transacci贸n lleva los datos de un estado v谩lido a otro. Se preserva la integridad de la base de datos seg煤n las reglas definidas.\n",
    "\n",
    "  * **Aislamiento (I)**: Asegura que las transacciones concurrentes se ejecuten de manera independiente, sin interferir entre s铆. Esto previene inconsistencias al leer datos que est谩n siendo modificados simult谩neamente.\n",
    "\n",
    "  * **Durabilidad (D)**: Una vez que una transacci贸n se ha completado, sus cambios son permanentes y persistir谩n incluso en caso de fallos del sistema.\n",
    "\n",
    "En conjunto, estas propiedades otorgan al Data Lake la fiabilidad de los sistemas de bases de datos tradicionales, lo cual es indispensable en entornos de producci贸n.\n",
    "\n",
    "-----\n",
    "\n",
    "## **Auditor铆a y Versionado de Datos**\n",
    "\n",
    "Estas garant铆as son posibles gracias al **registro de transacciones** (transaction log) que Delta Lake mantiene para cada tabla. Este registro es consultable y proporciona una completa auditor铆a de todas las operaciones realizadas.\n",
    "\n",
    "El comando `DESCRIBE HISTORY` permite inspeccionar este historial.\n",
    "\n",
    "**C贸digo:**\n",
    "\n",
    "```sql\n",
    "-- Consultar el historial de transacciones de la tabla de pedidos.\n",
    "DESCRIBE HISTORY curso_arquitecturas.pedidos_bronze;\n",
    "```\n",
    "\n",
    "**An谩lisis del Resultado:**\n",
    "\n",
    "La salida de este comando detalla cada operaci贸n (versi贸n, marca de tiempo, tipo de operaci贸n, par谩metros y usuario) que ha modificado la tabla.\n",
    "\n",
    "Esta capacidad de versionado es la base para la funcionalidad de \"Time Travel\", que permite consultar estados anteriores de los datos para fines de depuraci贸n, auditor铆a o restauraci贸n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97ab0d95-f8db-4267-b110-1147c5c0816b",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"operation\":255},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1755145252377}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "DESCRIBE HISTORY curso_arquitecturas.pedidos_bronze;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ef916b88-3476-4746-9afb-543b95b75b47",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### **Ejemplo 1: Viaje en el Tiempo por N煤mero de Versi贸n (`VERSION AS OF`)**\n",
    "\n",
    "La forma m谩s directa de viajar en el tiempo es pidiendo una versi贸n espec铆fica. Como nuestra tabla `pedidos_bronze` se cre贸 en una sola operaci贸n (`WRITE`), solo tiene la versi贸n 0 y la 1 (la creaci贸n y la escritura). Vamos a simular un cambio para poder comparar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b2df71d7-bfa9-44d0-a20d-00d2b6a3ff35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Primero, vamos a simular un cambio: borremos los pedidos del m茅todo de pago 'Efectivo'.\n",
    "-- Esto crear谩 la versi贸n 2 de la tabla.\n",
    "DELETE FROM curso_arquitecturas.pedidos_bronze WHERE metodo_pago = 'Efectivo';\n",
    "\n",
    "-- Ahora, comparemos la versi贸n m谩s reciente (2) con la anterior (1).\n",
    "SELECT \n",
    "  'Version 1 (Antes del borrado)' AS version, \n",
    "  COUNT(*) AS total_filas \n",
    "FROM curso_arquitecturas.pedidos_bronze VERSION AS OF 1\n",
    "UNION ALL\n",
    "SELECT \n",
    "  'Version 2 (Despu茅s del borrado)' AS version, \n",
    "  COUNT(*) AS total_filas \n",
    "FROM curso_arquitecturas.pedidos_bronze;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ef35f6f6-1031-45f6-af1e-7b9251c68e34",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Caso de uso:** Perfecto para restaurar una tabla a un estado anterior despu茅s de un error, como un borrado accidental."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "04425bf4-384a-4b3b-aa51-2fdd8f5c4932",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### **Ejemplo 2: Viaje en el Tiempo por Marca de Tiempo (`TIMESTAMP AS OF`)**\n",
    "\n",
    "A veces no conoces el n煤mero de la versi贸n, pero s铆 sabes la hora en que los datos estaban correctos. Puedes usar una marca de tiempo para consultar. La cadena de fecha y hora debe estar en el formato est谩ndar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5538c35-78d8-4297-aebd-a74e3ec2f116",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Consulta el estado de la tabla de usuarios ANTES de que ejecut谩ramos este notebook hoy.\n",
    "-- Reemplaza con una marca de tiempo anterior a la ejecuci贸n de la celda 2.\n",
    "SELECT \n",
    "  fecha_registro,\n",
    "  nombre\n",
    "FROM curso_arquitecturas.usuarios_bronze TIMESTAMP AS OF \"2025-08-13T23:00:00.000+0000\" -- Ajusta la fecha y hora a tu zona si es necesario\n",
    "LIMIT 5;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a6f8bf92-1295-4938-bd43-c678f3174edf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Caso de uso:** Investigar el estado de los datos justo antes de un despliegue o una ejecuci贸n de pipeline que pudo haber causado un problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b973395c-5d66-4759-bc2c-98801a4f54cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### **Ejemplo 3: Ver los Cambios Entre Dos Versiones (`table_changes`)**\n",
    "\n",
    "Esta es una funci贸n de tabla incre铆blemente 煤til para la auditor铆a. Te muestra exactamente qu茅 filas cambiaron entre dos versiones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a387aee8-6ba6-4c76-a378-c1871ab75455",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- **Paso 1: Habilitar Change Data Feed con la sintaxis correcta.**\n",
    "-- El nombre de la propiedad es 'delta.enableChangeDataFeed' (sin guion).\n",
    "ALTER TABLE curso_arquitecturas.pedidos_bronze SET TBLPROPERTIES ('delta.enableChangeDataFeed' = 'true');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08d1e3d0-064d-43a9-9770-7278f5520ca6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- **Paso 2: Realizar una nueva operaci贸n para generar un cambio que sea rastreado.**\n",
    "-- CDF solo rastrea los cambios OCURRIDOS DESPUS de su habilitaci贸n.\n",
    "-- Vamos a borrar los pedidos pagados con 'PayPal' para generar un nuevo historial.\n",
    "DELETE FROM curso_arquitecturas.pedidos_bronze WHERE metodo_pago = 'PayPal';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cfc95e20-cd95-400c-9c63-efedc842a817",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- **Paso 3: (Opcional pero recomendado) Consultar el historial para obtener los n煤meros de versi贸n.**\n",
    "DESCRIBE HISTORY curso_arquitecturas.pedidos_bronze;\n",
    "-- Anota la versi贸n de la operaci贸n 'DELETE' y la versi贸n inmediatamente anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c0ac272-d46f-41b1-988f-aabc2f172fed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- **Paso 4: Ejecutar 'table_changes' correctamente.**\n",
    "-- Ahora s铆 podemos ver las filas exactas que se eliminaron en la 煤ltima operaci贸n.\n",
    "-- Reemplace 'X' con la versi贸n ANTERIOR al DELETE y 'Y' con la versi贸n DEL DELETE.\n",
    "SELECT \n",
    "  *, \n",
    "  _commit_version as version_modificacion, \n",
    "  _commit_timestamp as fecha_modificacion \n",
    "FROM table_changes('curso_arquitecturas.pedidos_bronze', 5, 8); -- Ejemplo: table_changes('...', 2, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b6d2c269-c7b9-4153-8e72-23505f72dfa0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "**Caso de uso:** Auditor铆a fina. Identificar qu茅 datos espec铆ficos fueron alterados por una operaci贸n, por ejemplo, para un reporte de cumplimiento de normativas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a4bc1d6c-405d-4448-8ef2-88e82ac78bf9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### **Ejemplo 4: Restaurar una Tabla a una Versi贸n Anterior (`RESTORE`)**\n",
    "\n",
    "Si cometiste un error, no necesitas escribir c贸digo complejo para arreglarlo. `RESTORE` revierte la tabla a una versi贸n anterior, creando una nueva transacci贸n de restauraci贸n.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20d0a6db-63f0-4f3e-a6fc-eb078b48204f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- 隆Vamos a deshacer el borrado que hicimos en el Ejemplo 1!\n",
    "-- Esto restaurar谩 la tabla al estado de la versi贸n 0.\n",
    "RESTORE TABLE curso_arquitecturas.pedidos_bronze TO VERSION AS OF 0;\n",
    "\n",
    "-- Verifiquemos el historial para ver la nueva entrada de 'RESTORE'.\n",
    "DESCRIBE HISTORY curso_arquitecturas.pedidos_bronze;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "42ce7cd2-f5ba-4bc2-b50f-143d07557c0a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Caso de uso:** Recuperaci贸n de desastres de forma r谩pida y segura. Es la forma oficial de \"deshacer\" una mala operaci贸n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "73781018-60b5-4e49-94eb-af164fb33d32",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### **Ejemplo 5: Auditor铆a de Operaciones a Nivel de Archivo**\n",
    "\n",
    "El historial tambi茅n nos dice qu茅 archivos de datos (Parquet) fueron a帽adidos o eliminados en cada transacci贸n. Esto es 煤til para una depuraci贸n a bajo nivel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6371e0d-2a38-4335-9bcf-25bedaba277f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Miremos el historial de la tabla de devoluciones y veamos las m茅tricas de la operaci贸n de escritura.\n",
    "SELECT \n",
    "  version, \n",
    "  timestamp,\n",
    "  operation,\n",
    "  operationMetrics.numFiles AS archivos_escritos,\n",
    "  operationMetrics.numOutputRows AS filas_escritas,\n",
    "  operationMetrics.numOutputBytes AS bytes_escritos\n",
    "FROM (DESCRIBE HISTORY curso_arquitecturas.devoluciones_bronze);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1cd54338-9549-4b59-8006-56153656bbc0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Caso de uso:** Optimizaci贸n de rendimiento. Si ves que una operaci贸n est谩 generando miles de archivos peque帽os, es una se帽al de que necesitas optimizar la escritura (con t茅cnicas como `OPTIMIZE` o ajustando el tama帽o de los archivos)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fa554557-9f87-487c-ac03-787526ff0917",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### **Ejemplo 6: Auditor铆a Forense - Identificar el Notebook o Job que Modific贸 los Datos**\n",
    "\n",
    "**Caso de uso:** En un entorno colaborativo, m煤ltiples procesos y usuarios pueden modificar una tabla. Si ocurre un error, no basta con saber *qui茅n* hizo el cambio, sino *desde d贸nde* (qu茅 notebook o qu茅 job automatizado). Esta informaci贸n est谩 anidada en el historial.\n",
    "\n",
    "**C贸digo:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86374bd1-307b-45ee-bc64-5682dd908420",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Extraemos detalles del contexto de la ejecuci贸n de cada transacci贸n.\n",
    "-- 'notebook.notebookId' es extremadamente 煤til para la depuraci贸n.\n",
    "SELECT \n",
    "  version,\n",
    "  timestamp,\n",
    "  userName AS usuario,\n",
    "  operation,\n",
    "  operationParameters.mode,\n",
    "  notebook.notebookId AS id_del_notebook,\n",
    "  clusterId as id_del_cluster\n",
    "FROM \n",
    "  (DESCRIBE HISTORY curso_arquitecturas.pedidos_bronze);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cf26443a-5f1d-4fd8-a77b-3a6c1b9f3c6d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "**An谩lisis del Resultado:**\n",
    "Esta consulta enriquece el historial est谩ndar. La columna `id_del_notebook` te da un enlace directo al notebook que ejecut贸 la transacci贸n, permiti茅ndote ir directamente al c贸digo fuente que caus贸 el cambio. Es una de las herramientas de depuraci贸n m谩s potentes en Databricks.\n",
    "\n",
    "---\n",
    "### **Interpretaci贸n del Historial de la Tabla**\n",
    "\n",
    "Aqu铆 se desglosa la secuencia de eventos que ocurrieron, narrando la historia de la tabla desde su creaci贸n hasta su estado m谩s reciente.\n",
    "\n",
    "* **Versi贸n 0 (12 de Agosto): Creaci贸n Inicial**\n",
    "    La tabla fue creada por primera vez. Este fue el punto de partida.\n",
    "\n",
    "* **Versi贸n 1 (14 de Agosto): Reemplazo Total de la Tabla**\n",
    "    Dos d铆as despu茅s, la tabla fue completamente reemplazada usando `CREATE OR REPLACE TABLE`. Esto significa que todo el contenido de la versi贸n 0 fue descartado, y la tabla comenz贸 de nuevo. Este evento marca el inicio de la sesi贸n de trabajo principal.\n",
    "\n",
    "* **Versiones 2 y 3: Modificaci贸n y Mantenimiento**\n",
    "    Inmediatamente despu茅s del reemplazo, se realiz贸 una operaci贸n de borrado (`DELETE`). Justo despu茅s, se ejecut贸 un comando `OPTIMIZE`, que es una operaci贸n de mantenimiento para compactar archivos peque帽os y mejorar el rendimiento de lectura.\n",
    "\n",
    "* **Versiones 4 y 5: Habilitaci贸n de CDF y Nuevo Borrado**\n",
    "    La operaci贸n `SET TBLPROPERTIES` probablemente fue para habilitar el **Change Data Feed (CDF)** (`delta.enableChangeDataFeed`). Inmediatamente despu茅s, se realiz贸 otro `DELETE`, seguramente para probar la funcionalidad de `table_changes` que depende de CDF.\n",
    "\n",
    "* **Versiones 6, 7 y 8: Ciclo Adicional de Mantenimiento y Pruebas**\n",
    "    El patr贸n se repite: una optimizaci贸n (`OPTIMIZE`), seguida de otra modificaci贸n de propiedades y un `DELETE` final. Esto refuerza la idea de que se estaba llevando a cabo una sesi贸n de pruebas intensiva.\n",
    "\n",
    "* **Versiones 9 y 10: Recuperaci贸n de Datos (`RESTORE`)**\n",
    "    Estos son los eventos m谩s significativos. Las dos operaciones `RESTORE` consecutivas indican que el usuario revirti贸 la tabla a un estado anterior, deshaciendo efectivamente uno o m谩s de los borrados anteriores. Esto confirma que las operaciones `DELETE` eran parte de un experimento o un error que se necesitaba corregir.\n",
    "\n",
    "---\n",
    "### **Observaciones Clave **\n",
    "\n",
    "1.  **Ausencia del `id_del_notebook`**: El hecho de que `id_del_notebook` sea `null` en todas las operaciones es una pista muy importante. Generalmente, esto significa que los comandos SQL no se ejecutaron desde un notebook de Databricks (con un cl煤ster de computaci贸n), sino directamente a trav茅s del **Editor de SQL de Databricks** conectado a un **SQL Warehouse**.\n",
    "\n",
    "2.  **Sesi贸n de Pruebas Intensiva**: La r谩pida sucesi贸n de operaciones variadas (`DELETE`, `OPTIMIZE`, `SET TBLPROPERTIES`, `RESTORE`) en un corto per铆odo de tiempo (la mayor铆a en menos de 30 minutos el 14 de agosto) es un claro indicador de una sesi贸n de desarrollo o depuraci贸n, no de un pipeline de producci贸n automatizado.\n",
    "\n",
    "3.  **Uso de Funcionalidades Avanzadas**: El historial demuestra un uso pr谩ctico de las caracter铆sticas que hacen poderoso a Delta Lake: la capacidad de modificar, optimizar, habilitar funciones y, lo m谩s importante, restaurar la tabla a un punto anterior en el tiempo de forma segura.\n",
    "\n",
    "El historial narra lo que el ingeniero de datos hizo desde el 14 de agosto de 2025, someti贸 la tabla a una serie de pruebas rigurosas para validar o experimentar con las capacidades de modificaci贸n y recuperaci贸n de Delta Lake, probablemente trabajando desde el entorno de Databricks SQL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dab5011a-0db4-40e4-aade-e0ad2bdcb398",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### **Ejemplo 7: An谩lisis Comparativo - Ver el \"Antes y Despu茅s\" de una Fila**\n",
    "\n",
    "**Caso de uso:** Se ha ejecutado una operaci贸n `MERGE` para actualizar precios o estados, y necesitas validar que los cambios se aplicaron correctamente, comparando el valor antiguo con el nuevo para filas espec铆ficas.\n",
    "\n",
    "**C贸digo:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18e745b7-2a3e-4061-8b49-e85344836173",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Paso 1: Simular una actualizaci贸n en la tabla de productos.\n",
    "-- Actualizaremos el precio de un producto y la categor铆a de otro.\n",
    "UPDATE curso_arquitecturas.productos_bronze \n",
    "SET precio_unitario = 99.99 \n",
    "WHERE id_producto = 2001;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7e138da-1a5f-4597-bad1-9c77293e341a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Paso 2: Obtener la 煤ltima versi贸n del historial para comparar.\n",
    "-- Asumamos que la operaci贸n UPDATE fue la versi贸n 2. La versi贸n anterior era la 1.\n",
    "\n",
    "DESCRIBE HISTORY curso_arquitecturas.productos_bronze\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18b24f4a-b39f-4796-9c71-70bfde4f84d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- Paso 3: Comparar los datos de la misma tabla en dos momentos del tiempo.\n",
    "SELECT\n",
    "  antes.id_producto,\n",
    "  antes.nombre_producto,\n",
    "  antes.precio_unitario AS precio_anterior,\n",
    "  despues.precio_unitario AS precio_nuevo,\n",
    "  antes.categoria AS categoria_anterior,\n",
    "  despues.categoria AS categoria_nueva\n",
    "FROM \n",
    "  curso_arquitecturas.productos_bronze VERSION AS OF 1 AS antes\n",
    "INNER JOIN \n",
    "  curso_arquitecturas.productos_bronze AS despues \n",
    "  ON antes.id_producto = despues.id_producto\n",
    "WHERE \n",
    "  antes.precio_unitario <> despues.precio_unitario OR antes.categoria <> despues.categoria;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a88c9cbc-3cf0-4247-9802-9610618426bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**An谩lisis del Resultado:**\n",
    "Esta consulta te mostrar谩 煤nicamente las filas que han sufrido una modificaci贸n entre las dos versiones, presentando el valor antiguo y el nuevo en la misma l铆nea. Es un m茅todo extremadamente eficaz para validar la l贸gica de negocio en operaciones de `UPDATE` o `MERGE`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "94639489-1eb4-4a50-8ea0-2d905f897a55",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### **Ejemplo 8: Creaci贸n de un Log de Auditor铆a Permanente**\n",
    "\n",
    "**Caso de uso:** El resultado de `DESCRIBE HISTORY` es una consulta temporal. Para un cumplimiento normativo o una auditor铆a a largo plazo, necesitas almacenar este historial de forma permanente en su propia tabla Delta.\n",
    "\n",
    "**C贸digo:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9cc13223-c2d3-4f06-acac-c6ddb4f0fd17",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Usamos PySpark para mayor flexibilidad al manejar el DataFrame del historial.\n",
    "\n",
    "# Paso 1: Ejecutar DESCRIBE HISTORY y cargarlo en un DataFrame.\n",
    "history_df = spark.sql(\"DESCRIBE HISTORY curso_arquitecturas.pedidos_bronze\")\n",
    "\n",
    "# Paso 2: Seleccionar y aplanar las columnas que nos interesan.\n",
    "audit_log_df = history_df.select(\n",
    "    \"version\",\n",
    "    \"timestamp\",\n",
    "    \"userId\",\n",
    "    \"userName\",\n",
    "    \"operation\",\n",
    "    \"operationParameters\",\n",
    "    \"notebook.notebookId\"\n",
    ")\n",
    "\n",
    "# Paso 3: Guardar este log en una nueva tabla Delta.\n",
    "# Usamos el modo 'append' para poder ejecutar esto peri贸dicamente y a帽adir el nuevo historial.\n",
    "audit_log_df.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"append\") \\\n",
    "    .saveAsTable(\"log_auditoria_pedidos\")\n",
    "\n",
    "print(\"Log de auditor铆a guardado exitosamente.\")\n",
    "\n",
    "# Consultar el log permanente.\n",
    "display(spark.sql(\"SELECT * FROM log_auditoria_pedidos ORDER BY version DESC\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c06eb7a6-9dd6-4c43-9b4a-4700c4f283f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**An谩lisis del Resultado:**\n",
    "Has creado una tabla `log_auditoria_pedidos` que acumula el historial de cambios de tu tabla principal. Puedes construir alertas o informes sobre esta tabla para monitorear actividades sospechosas o simplemente para tener un registro inmutable de todas las transacciones a lo largo del tiempo."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "dependencies": [
     "faker"
    ],
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7390553139736518,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "sesion_2_auditoria",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
